{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "from patsy import dmatrices\n",
    "from sklearn.cross_validation import train_test_split,StratifiedShuffleSplit,StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import neighbors\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#from sklearn.cross_validation import \n",
    "#from sklearn.cross_validation import \n",
    "import scipy.sparse\n",
    "import sklearn.cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yelp = pd.read_csv(\"yelp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "high_mask = yelp['stars'] > 3\n",
    "yelp['High'] = 0\n",
    "yelp.ix[high_mask, 'High'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Task A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "formula = 'High ~ 0 + votes_cool + votes_funny + votes_useful + Cheap + Moderate + Expensive  ' + \\\n",
    "' + VeryExpensive + American + Chinese + French + Japanese + Indian + Italian + Greek ' + \\\n",
    "' + Mediterranean + Mexican + Thai + Vietnamese + Others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y, X = dmatrices(formula, yelp, return_type='dataframe')\n",
    "y = Y['High'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = StratifiedShuffleSplit(y, n_iter = 1, test_size = 0.3, train_size = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedShuffleSplit(labels=[ 0.  0.  1. ...,  1.  0.  1.], n_iter=1, test_size=0.3, random_state=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DF_X = DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14215 15825 14171 ...,  4988 13549  5476]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in index:\n",
    "    print(train_index)\n",
    "    X_train, X_test = DF_X.iloc[train_index,], DF_X.iloc[test_index,]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>votes_cool</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>votes_useful</th>\n",
       "      <th>Cheap</th>\n",
       "      <th>Moderate</th>\n",
       "      <th>Expensive</th>\n",
       "      <th>VeryExpensive</th>\n",
       "      <th>American</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>French</th>\n",
       "      <th>Japanese</th>\n",
       "      <th>Indian</th>\n",
       "      <th>Italian</th>\n",
       "      <th>Greek</th>\n",
       "      <th>Mediterranean</th>\n",
       "      <th>Mexican</th>\n",
       "      <th>Thai</th>\n",
       "      <th>Vietnamese</th>\n",
       "      <th>Others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14215</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15825</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14171</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12042</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       votes_cool  votes_funny  votes_useful  Cheap  Moderate  Expensive  \\\n",
       "14215           0            0             0      0         1          0   \n",
       "15825           0            0             0      1         0          0   \n",
       "14171           1            1             3      0         1          0   \n",
       "12042           1            1             2      0         1          0   \n",
       "7100            2            2             3      0         0          1   \n",
       "\n",
       "       VeryExpensive  American  Chinese  French  Japanese  Indian  Italian  \\\n",
       "14215              0         0        0       0         0       0        1   \n",
       "15825              0         0        0       0         0       0        0   \n",
       "14171              0         0        0       0         0       0        1   \n",
       "12042              0         0        0       0         0       1        0   \n",
       "7100               0         1        0       0         0       0        0   \n",
       "\n",
       "       Greek  Mediterranean  Mexican  Thai  Vietnamese  Others  \n",
       "14215      0              0        0     0           0       0  \n",
       "15825      1              1        0     0           0       0  \n",
       "14171      0              0        0     0           0       0  \n",
       "12042      0              0        0     0           0       0  \n",
       "7100       0              0        0     0           0       0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "logistic_result = logistic_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.684691763697\n"
     ]
    }
   ],
   "source": [
    "logistic_train_prediction = logistic_model.predict(X_train)\n",
    "print metrics.accuracy_score(y_train, logistic_train_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.684\n"
     ]
    }
   ],
   "source": [
    "logistic_test_prediction = logistic_model.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, logistic_test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn_model = neighbors.KNeighborsClassifier(n_neighbors=15, weights='uniform', p=2)\n",
    "knn_result = knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67933423816\n"
     ]
    }
   ],
   "source": [
    "knn_train_prediction = knn_model.predict(X_train)\n",
    "print metrics.accuracy_score(y_train, knn_train_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.662333333333\n"
     ]
    }
   ],
   "source": [
    "knn_test_prediction = knn_model.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, knn_test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Task B: Classification on Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234567)\n",
    "train = yelp.sample(int(len(yelp)*0.7), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = yelp[~yelp.index.isin(train.index.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = train['Review']\n",
    "train_y = train['High']\n",
    "test_x = test['Review']\n",
    "test_y = test['High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=0,smooth_idf=True, strip_accents='unicode', norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_classification (v):\n",
    "    X_transform=v.fit_transform(train_x)\n",
    "    X_test=v.transform(test_x)\n",
    "    \n",
    "    nb_classifier = MultinomialNB().fit(X_transform, train_y)\n",
    "    y_nb_predicted = nb_classifier.predict(X_test)\n",
    "    \n",
    "    predict_y=Series(y_nb_predicted).reset_index()[0]\n",
    "    df=pd.DataFrame()\n",
    "    df['Predicted']=predict_y\n",
    "    df['Actual']=test_y.reset_index()['High']\n",
    "    \n",
    "    print \"Percent Correct\\n\",round((df['Predicted']==df['Actual']).mean()*100,3)\n",
    "    print \"\\nConfusion Matrix\\n\",pd.crosstab(index=df['Actual'],columns=df['Predicted'])\n",
    "    print \"\\nProportion Table\\n\", pd.crosstab(index=df['Actual'],columns=df['Predicted']).apply(lambda r: r/r.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Correct\n",
      "68.033\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted   0     1\n",
      "Actual             \n",
      "0          66  1917\n",
      "1           1  4016\n",
      "\n",
      "Proportion Table\n",
      "Predicted         0         1\n",
      "Actual                       \n",
      "0          0.033283  0.966717\n",
      "1          0.000249  0.999751\n"
     ]
    }
   ],
   "source": [
    "text_classification(vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###Undersampling data set to ensure 50/50 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "highs=yelp[yelp['High']==1]\n",
    "lows=yelp[yelp['High']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_high=highs.sample(len(lows),replace=False).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample=sample_high.append(lows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=sample.sample(int(0.7*len(sample)),replace=False).copy()\n",
    "test=sample[~sample.index.isin(train.index.values)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = train['Review']\n",
    "train_y = train['High']\n",
    "test_x = test['Review']\n",
    "test_y = test['High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Correct\n",
      "81.593\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted     0     1\n",
      "Actual               \n",
      "0          1686   254\n",
      "1           458  1470\n",
      "\n",
      "Proportion Table\n",
      "Predicted         0         1\n",
      "Actual                       \n",
      "0          0.869072  0.130928\n",
      "1          0.237552  0.762448\n"
     ]
    }
   ],
   "source": [
    "text_classification(vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Task C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_transform=vectorizer.fit_transform(train_x) #just the reviews\n",
    "sam=train.drop([\"Review\", \"stars\"], axis=1).copy()\n",
    "samsparse=scipy.sparse.csr_matrix(sam.to_sparse()) #sparsing the numeric\n",
    "surprise=scipy.sparse.hstack([X_transform, samsparse]) #combining numeric and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test=vectorizer.transform(test_x) #repeating above for test\n",
    "samt=test.drop([\"Review\", \"stars\"], axis=1).copy() #removing irrelevant\n",
    "samsparset=scipy.sparse.csr_matrix(samt.to_sparse()) #sparsing numeric \n",
    "surpriset=scipy.sparse.hstack([X_test, samsparset]) #combining numeric and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB().fit(surprise, train_y)\n",
    "y_nb_predicted = nb_classifier.predict(surpriset)\n",
    "    \n",
    "predict_y=Series(y_nb_predicted).reset_index()[0]\n",
    "df=pd.DataFrame()\n",
    "df['Predicted']=predict_y\n",
    "df['Actual']=test_y.reset_index()['High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Correct\n",
      "98.035\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted     0     1\n",
      "Actual               \n",
      "0          1864    76\n",
      "1             0  1928\n",
      "\n",
      "Proportion Table\n",
      "Predicted         0         1\n",
      "Actual                       \n",
      "0          0.960825  0.039175\n",
      "1          0.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "print \"Percent Correct\\n\",round((df['Predicted']==df['Actual']).mean()*100,3)\n",
    "print \"\\nConfusion Matrix\\n\",pd.crosstab(index=df['Actual'],columns=df['Predicted'])\n",
    "print \"\\nProportion Table\\n\", pd.crosstab(index=df['Actual'],columns=df['Predicted']).apply(lambda r: r/r.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Correct\n",
      "98.881\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted     0     1\n",
      "Actual               \n",
      "0          4405   101\n",
      "1             0  4518\n",
      "\n",
      "Proportion Table\n",
      "Predicted         0         1\n",
      "Actual                       \n",
      "0          0.977585  0.022415\n",
      "1          0.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "y_nb_predicted = nb_classifier.predict(surprise)\n",
    "predict_y=Series(y_nb_predicted).reset_index()[0]\n",
    "df=pd.DataFrame()\n",
    "df['Predicted']=predict_y\n",
    "df['Actual']=train_y.reset_index()['High']\n",
    "print \"Percent Correct\\n\",round((df['Predicted']==df['Actual']).mean()*100,3)\n",
    "print \"\\nConfusion Matrix\\n\",pd.crosstab(index=df['Actual'],columns=df['Predicted'])\n",
    "print \"\\nProportion Table\\n\", pd.crosstab(index=df['Actual'],columns=df['Predicted']).apply(lambda r: r/r.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cross Validation (because this is too good to be true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def yelper(removeList,sample=sample):\n",
    "    train=sample.sample(int(0.7*len(sample)),replace=False).copy()\n",
    "    test=sample[~sample.index.isin(train.index.values)].copy()\n",
    "    \n",
    "    train_x = train['Review']\n",
    "    train_y = train['High']\n",
    "    test_x = test['Review']\n",
    "    test_y = test['High']\n",
    "    \n",
    "    X_transform=vectorizer.fit_transform(train_x) #just the reviews\n",
    "    sam=train.drop(removeList, axis=1).copy()\n",
    "    samsparse=scipy.sparse.csr_matrix(sam.to_sparse()) #sparsing the numeric\n",
    "    surprise=scipy.sparse.hstack([X_transform, samsparse]) #combining numeric and text\n",
    "    \n",
    "    X_test=vectorizer.transform(test_x) #repeating above for test\n",
    "    samt=test.drop(removeList, axis=1).copy() #removing irrelevant\n",
    "    samsparset=scipy.sparse.csr_matrix(samt.to_sparse()) #sparsing numeric \n",
    "    surpriset=scipy.sparse.hstack([X_test, samsparset]) #combining numeric and text\n",
    "    \n",
    "    nb_classifier = MultinomialNB().fit(surprise, train_y)\n",
    "    y_nb_predicted = nb_classifier.predict(surpriset)\n",
    "    \n",
    "    predict_y=Series(y_nb_predicted).reset_index()[0]\n",
    "    df=pd.DataFrame()\n",
    "    df['Predicted']=predict_y\n",
    "    df['Actual']=test_y.reset_index()['High']\n",
    "    \n",
    "    print \"Percent Correct\\n\",round((df['Predicted']==df['Actual']).mean()*100,3)\n",
    "    print \"\\nConfusion Matrix\\n\",pd.crosstab(index=df['Actual'],columns=df['Predicted'])\n",
    "    print \"\\nProportion Table\\n\", pd.crosstab(index=df['Actual'],columns=df['Predicted']).apply(lambda r: r/r.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Correct\n",
      "79.524\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted     0     1\n",
      "Actual               \n",
      "0          1541   398\n",
      "1           394  1535\n",
      "\n",
      "Proportion Table\n",
      "Predicted         0         1\n",
      "Actual                       \n",
      "0          0.794740  0.205260\n",
      "1          0.204251  0.795749\n"
     ]
    }
   ],
   "source": [
    "rL=[\"Review\",\"stars\",\"High\"]\n",
    "yelper(rL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(sample['High'], n_folds=3, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Correct\n",
      "80.222\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted     0     1\n",
      "Actual               \n",
      "0          1572   344\n",
      "1           421  1531\n",
      "\n",
      "Proportion Table\n",
      "Predicted         0         1\n",
      "Actual                       \n",
      "0          0.820459  0.179541\n",
      "1          0.215676  0.784324\n"
     ]
    }
   ],
   "source": [
    "yelper(rL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Correct\n",
      "80.119\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted     0     1\n",
      "Actual               \n",
      "0          1565   426\n",
      "1           343  1534\n",
      "\n",
      "Proportion Table\n",
      "Predicted         0         1\n",
      "Actual                       \n",
      "0          0.786037  0.213963\n",
      "1          0.182738  0.817262\n"
     ]
    }
   ],
   "source": [
    "yelper(rL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Correct\n",
      "80.3\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted     0     1\n",
      "Actual               \n",
      "0          1572   369\n",
      "1           393  1534\n",
      "\n",
      "Proportion Table\n",
      "Predicted         0         1\n",
      "Actual                       \n",
      "0          0.809892  0.190108\n",
      "1          0.203944  0.796056\n"
     ]
    }
   ],
   "source": [
    "yelper(rL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Part D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawsentiment = pd.read_excel(r'C:\\Users\\beins_000\\Documents\\GitHub\\Text_Mining_MIS184N\\Group_Assignment_2\\Yelp_Review_Data_Results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Pos Senti</th>\n",
       "      <th>Neg Senti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLOSED            This JB s locati...</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is just a basic (albeit mini) chain greas...</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whenever I offer to take my mom out to lunch s...</td>\n",
       "      <td>4</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If I say it wasn t as bad as I was expecting i...</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I ve always said if the guacamole  chips and s...</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Had the signature Black Chile entree.  It was ...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>After hitting up the bank to sign some paper w...</td>\n",
       "      <td>4</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Great happy hour deals here! I loved the Cotij...</td>\n",
       "      <td>4</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fine. Just fine. C /B- average-- all around.  ...</td>\n",
       "      <td>4</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>beautiful atmosphere...good prices (for the bi...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Went there tonight. For a saturday night  it w...</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>This is the quintessential Mexican restaurant ...</td>\n",
       "      <td>4</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Came to this place to show some friends  from ...</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Black Chile Mexican Grill looks like a commerc...</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pft. Eh.  This place is pretty cool I guess.  ...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>It s definitely not the best Mexican food I ha...</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The food here is outstanding -- you can order ...</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>really good gourmet Mexican  we got the corn c...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>New restaurant to the Biltmore.  Happy hour is...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fan-freaking-tastic shrimp tacos   Modella Esp...</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Review  Pos Senti  Neg Senti\n",
       "0               CLOSED            This JB s locati...          2         -2\n",
       "1   This is just a basic (albeit mini) chain greas...          2         -2\n",
       "2   Whenever I offer to take my mom out to lunch s...          4         -4\n",
       "3   If I say it wasn t as bad as I was expecting i...          3         -3\n",
       "4   I ve always said if the guacamole  chips and s...          3         -3\n",
       "5   Had the signature Black Chile entree.  It was ...          3         -1\n",
       "6   After hitting up the bank to sign some paper w...          4         -4\n",
       "7   Great happy hour deals here! I loved the Cotij...          4         -5\n",
       "8   Fine. Just fine. C /B- average-- all around.  ...          4         -3\n",
       "9   beautiful atmosphere...good prices (for the bi...          3         -1\n",
       "10  Went there tonight. For a saturday night  it w...          2         -2\n",
       "11  This is the quintessential Mexican restaurant ...          4         -3\n",
       "12  Came to this place to show some friends  from ...          2         -3\n",
       "13  Black Chile Mexican Grill looks like a commerc...          3         -3\n",
       "14  Pft. Eh.  This place is pretty cool I guess.  ...          3         -1\n",
       "15  It s definitely not the best Mexican food I ha...          3         -2\n",
       "16  The food here is outstanding -- you can order ...          4         -2\n",
       "17  really good gourmet Mexican  we got the corn c...          3         -1\n",
       "18  New restaurant to the Biltmore.  Happy hour is...          4         -1\n",
       "19  Fan-freaking-tastic shrimp tacos   Modella Esp...          3         -2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawsentiment.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawsentiment['True_Sentiment'] = rawsentiment['Pos Senti'] + rawsentiment['Neg Senti']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Part E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=300, n_clusters=2, n_init=10,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTMReviews = vectorizer.fit_transform(sample['Review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-111-543d08913994>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-111-543d08913994>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    from sklearn.cluster import k_means_k_means_.euclidean_distances\u001b[0m\n\u001b[1;37m                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.metrics.pairwise import cosine_similarity\n",
    "#def new_euclidean_distances(X, Y=None, Y_norm_squared=None, squared=False):\n",
    "#    return cosine_similarity(X,Y)\n",
    "\n",
    "# monkey patch (ensure cosine dist function is used)\n",
    "#from sklearn.cluster import k_means_k_means_.euclidean_distances\n",
    "#k_means_.euclidean_distances = new_euclidean_distances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster = sklearn.cluster.KMeans(n_clusters=2, random_state = 1)\n",
    "clusterout = Cluster.fit(DTMReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series_clusters = Series(clusterout.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample['Cluster'] = series_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.concat([sample, series_clusters], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>votes_cool</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>votes_useful</th>\n",
       "      <th>Cheap</th>\n",
       "      <th>Moderate</th>\n",
       "      <th>Expensive</th>\n",
       "      <th>VeryExpensive</th>\n",
       "      <th>American</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>...</th>\n",
       "      <th>Italian</th>\n",
       "      <th>Greek</th>\n",
       "      <th>Mediterranean</th>\n",
       "      <th>Mexican</th>\n",
       "      <th>Thai</th>\n",
       "      <th>Vietnamese</th>\n",
       "      <th>Others</th>\n",
       "      <th>Review</th>\n",
       "      <th>High</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I can t believe I m the first person to review...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>We were told that this is the best place to ea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>After having visited the Tempe location  I was...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Dick s and the related restaurant  Richardson ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>My husband and I went  to Roma Garden for dinn...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars  votes_cool  votes_funny  votes_useful  Cheap  Moderate  Expensive  \\\n",
       "0      4           1            0             2      0         1          0   \n",
       "1      5           1            0             0      0         1          0   \n",
       "2      5          15           11            15      0         1          0   \n",
       "3      5           2            1             3      0         1          0   \n",
       "4      5           0            0             0      0         1          0   \n",
       "\n",
       "   VeryExpensive  American  Chinese   ...     Italian  Greek  Mediterranean  \\\n",
       "0              0         0        0   ...           1      0              0   \n",
       "1              0         1        0   ...           0      0              0   \n",
       "2              0         0        0   ...           0      0              0   \n",
       "3              0         1        0   ...           0      0              0   \n",
       "4              0         0        0   ...           1      0              0   \n",
       "\n",
       "   Mexican  Thai  Vietnamese  Others  \\\n",
       "0        0     0           0       0   \n",
       "1        0     0           0       0   \n",
       "2        0     0           0       1   \n",
       "3        1     0           0       0   \n",
       "4        0     0           0       0   \n",
       "\n",
       "                                              Review  High  Cluster  \n",
       "0  I can t believe I m the first person to review...     1        1  \n",
       "1  We were told that this is the best place to ea...     1        0  \n",
       "2  After having visited the Tempe location  I was...     1        0  \n",
       "3  Dick s and the related restaurant  Richardson ...     1        1  \n",
       "4  My husband and I went  to Roma Garden for dinn...     1        0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      "Cluster     0     1\n",
      "High               \n",
      "0        3425  3021\n",
      "1        2287  4159\n",
      "\n",
      "Percent Correct\n",
      "41.173\n",
      "\n",
      "Proportion Table\n",
      "Cluster         0         1\n",
      "High                       \n",
      "0        0.531337  0.468663\n",
      "1        0.354794  0.645206\n"
     ]
    }
   ],
   "source": [
    "print \"Confusion Matrix \\n\", pd.crosstab(index=sample['High'],columns=sample['Cluster'])\n",
    "print \"\\nPercent Correct\\n\", round((sample['High']!=sample['Cluster']).mean()*100,3)\n",
    "print \"\\nProportion Table\\n\", pd.crosstab(index=sample['High'],columns=sample['Cluster']).apply(lambda r: r/r.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Part F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
