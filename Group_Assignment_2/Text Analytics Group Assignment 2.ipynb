{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "from patsy import dmatrices\n",
    "from sklearn.cross_validation import train_test_split,StratifiedShuffleSplit,StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import neighbors\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#from sklearn.cross_validation import \n",
    "#from sklearn.cross_validation import \n",
    "import scipy.sparse\n",
    "import sklearn.cluster\n",
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yelp = pd.read_csv(\"yelp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "high_mask = yelp['stars'] > 3\n",
    "yelp['High'] = 0\n",
    "yelp.ix[high_mask, 'High'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Task A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "formula = 'High ~ 0 + votes_cool + votes_funny + votes_useful + Cheap + Moderate + Expensive  ' + \\\n",
    "' + VeryExpensive + American + Chinese + French + Japanese + Indian + Italian + Greek ' + \\\n",
    "' + Mediterranean + Mexican + Thai + Vietnamese + Others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y, X = dmatrices(formula, yelp, return_type='dataframe')\n",
    "y = Y['High'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = StratifiedShuffleSplit(y, n_iter = 1, test_size = 0.3, train_size = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedShuffleSplit(labels=[ 0.  0.  1. ...,  1.  0.  1.], n_iter=1, test_size=0.3, random_state=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DF_X = DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15237  6989 16386 ...,  5757 18356   478]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in index:\n",
    "    print(train_index)\n",
    "    X_train, X_test = DF_X.iloc[train_index,], DF_X.iloc[test_index,]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>votes_cool</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>votes_useful</th>\n",
       "      <th>Cheap</th>\n",
       "      <th>Moderate</th>\n",
       "      <th>Expensive</th>\n",
       "      <th>VeryExpensive</th>\n",
       "      <th>American</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>French</th>\n",
       "      <th>Japanese</th>\n",
       "      <th>Indian</th>\n",
       "      <th>Italian</th>\n",
       "      <th>Greek</th>\n",
       "      <th>Mediterranean</th>\n",
       "      <th>Mexican</th>\n",
       "      <th>Thai</th>\n",
       "      <th>Vietnamese</th>\n",
       "      <th>Others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15237</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16386</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9218</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       votes_cool  votes_funny  votes_useful  Cheap  Moderate  Expensive  \\\n",
       "15237           0            0             0      0         1          0   \n",
       "6989            2            1             4      0         1          0   \n",
       "16386           1            1             1      0         1          0   \n",
       "1614            0            0             0      0         1          0   \n",
       "9218            0            0             0      0         1          0   \n",
       "\n",
       "       VeryExpensive  American  Chinese  French  Japanese  Indian  Italian  \\\n",
       "15237              0         1        0       0         0       0        0   \n",
       "6989               0         1        0       0         0       0        0   \n",
       "16386              0         0        0       0         0       0        0   \n",
       "1614               0         0        1       0         0       0        0   \n",
       "9218               0         0        0       0         0       0        0   \n",
       "\n",
       "       Greek  Mediterranean  Mexican  Thai  Vietnamese  Others  \n",
       "15237      0              1        0     0           0       0  \n",
       "6989       0              0        0     0           0       0  \n",
       "16386      0              0        1     0           0       0  \n",
       "1614       0              0        0     0           0       0  \n",
       "9218       0              0        1     0           0       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "logistic_result = logistic_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.683977426959\n"
     ]
    }
   ],
   "source": [
    "logistic_train_prediction = logistic_model.predict(X_train)\n",
    "print metrics.accuracy_score(y_train, logistic_train_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.684\n"
     ]
    }
   ],
   "source": [
    "logistic_test_prediction = logistic_model.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, logistic_test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn_model = neighbors.KNeighborsClassifier(n_neighbors=15, weights='uniform', p=2)\n",
    "knn_result = knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.695406814772\n"
     ]
    }
   ],
   "source": [
    "knn_train_prediction = knn_model.predict(X_train)\n",
    "print metrics.accuracy_score(y_train, knn_train_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6815\n"
     ]
    }
   ],
   "source": [
    "knn_test_prediction = knn_model.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, knn_test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Task B: Classification on Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234567)\n",
    "train = yelp.sample(int(len(yelp)*0.7), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = yelp[~yelp.index.isin(train.index.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = train['Review']\n",
    "train_y = train['High']\n",
    "test_x = test['Review']\n",
    "test_y = test['High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=0,smooth_idf=True, strip_accents='unicode', norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_classification (v):\n",
    "    X_transform=v.fit_transform(train_x)\n",
    "    X_test=v.transform(test_x)\n",
    "    \n",
    "    nb_classifier = MultinomialNB().fit(X_transform, train_y)\n",
    "    y_nb_predicted = nb_classifier.predict(X_test)\n",
    "    \n",
    "    predict_y=Series(y_nb_predicted).reset_index()[0]\n",
    "    df=pd.DataFrame()\n",
    "    df['Predicted']=predict_y\n",
    "    df['Actual']=test_y.reset_index()['High']\n",
    "    \n",
    "    print \"Percent Correct\\n\",round((df['Predicted']==df['Actual']).mean()*100,3)\n",
    "    print \"\\nConfusion Matrix\\n\",pd.crosstab(index=df['Actual'],columns=df['Predicted'])\n",
    "    print \"\\nProportion Table\\n\", pd.crosstab(index=df['Actual'],columns=df['Predicted']).apply(lambda r: r/r.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Correct\n",
      "69.617\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted   0     1\n",
      "Actual             \n",
      "0          86  1821\n",
      "1           2  4091\n",
      "\n",
      "Proportion Table\n",
      "Predicted         0         1\n",
      "Actual                       \n",
      "0          0.045097  0.954903\n",
      "1          0.000489  0.999511\n"
     ]
    }
   ],
   "source": [
    "text_classification(vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###Undersampling data set to ensure 50/50 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "highs=yelp[yelp['High']==1]\n",
    "lows=yelp[yelp['High']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_high=highs.sample(len(lows),replace=False).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample=sample_high.append(lows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=sample.sample(int(0.7*len(sample)),replace=False).copy()\n",
    "test=sample[~sample.index.isin(train.index.values)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = train['Review']\n",
    "train_y = train['High']\n",
    "test_x = test['Review']\n",
    "test_y = test['High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Correct\n",
      "81.334\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted     0     1\n",
      "Actual               \n",
      "0          1652   280\n",
      "1           442  1494\n",
      "\n",
      "Proportion Table\n",
      "Predicted         0         1\n",
      "Actual                       \n",
      "0          0.855072  0.144928\n",
      "1          0.228306  0.771694\n"
     ]
    }
   ],
   "source": [
    "text_classification(vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Task C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_transform=vectorizer.fit_transform(train_x) #just the reviews\n",
    "sam=train.drop([\"Review\", \"stars\"], axis=1).copy()\n",
    "samsparse=scipy.sparse.csr_matrix(sam.to_sparse()) #sparsing the numeric\n",
    "surprise=scipy.sparse.hstack([X_transform, samsparse]) #combining numeric and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test=vectorizer.transform(test_x) #repeating above for test\n",
    "samt=test.drop([\"Review\", \"stars\"], axis=1).copy() #removing irrelevant\n",
    "samsparset=scipy.sparse.csr_matrix(samt.to_sparse()) #sparsing numeric \n",
    "surpriset=scipy.sparse.hstack([X_test, samsparset]) #combining numeric and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB().fit(surprise, train_y)\n",
    "y_nb_predicted = nb_classifier.predict(surpriset)\n",
    "    \n",
    "predict_y=Series(y_nb_predicted).reset_index()[0]\n",
    "df=pd.DataFrame()\n",
    "df['Predicted']=predict_y\n",
    "df['Actual']=test_y.reset_index()['High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Correct\n",
      "97.854\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted     0     1\n",
      "Actual               \n",
      "0          1849    83\n",
      "1             0  1936\n",
      "\n",
      "Proportion Table\n",
      "Predicted         0         1\n",
      "Actual                       \n",
      "0          0.957039  0.042961\n",
      "1          0.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "print \"Percent Correct\\n\",round((df['Predicted']==df['Actual']).mean()*100,3)\n",
    "print \"\\nConfusion Matrix\\n\",pd.crosstab(index=df['Actual'],columns=df['Predicted'])\n",
    "print \"\\nProportion Table\\n\", pd.crosstab(index=df['Actual'],columns=df['Predicted']).apply(lambda r: r/r.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Correct\n",
      "98.692\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted     0     1\n",
      "Actual               \n",
      "0          4396   118\n",
      "1             0  4510\n",
      "\n",
      "Proportion Table\n",
      "Predicted         0         1\n",
      "Actual                       \n",
      "0          0.973859  0.026141\n",
      "1          0.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "y_nb_predicted = nb_classifier.predict(surprise)\n",
    "predict_y=Series(y_nb_predicted).reset_index()[0]\n",
    "df=pd.DataFrame()\n",
    "df['Predicted']=predict_y\n",
    "df['Actual']=train_y.reset_index()['High']\n",
    "print \"Percent Correct\\n\",round((df['Predicted']==df['Actual']).mean()*100,3)\n",
    "print \"\\nConfusion Matrix\\n\",pd.crosstab(index=df['Actual'],columns=df['Predicted'])\n",
    "print \"\\nProportion Table\\n\", pd.crosstab(index=df['Actual'],columns=df['Predicted']).apply(lambda r: r/r.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cross Validation (because this is too good to be true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def yelper(removeList,sample=sample):\n",
    "    train=sample.sample(int(0.7*len(sample)),replace=False).copy()\n",
    "    test=sample[~sample.index.isin(train.index.values)].copy()\n",
    "    \n",
    "    train_x = train['Review']\n",
    "    train_y = train['High']\n",
    "    test_x = test['Review']\n",
    "    test_y = test['High']\n",
    "    \n",
    "    X_transform=vectorizer.fit_transform(train_x) #just the reviews\n",
    "    sam=train.drop(removeList, axis=1).copy()\n",
    "    samsparse=scipy.sparse.csr_matrix(sam.to_sparse()) #sparsing the numeric\n",
    "    surprise=scipy.sparse.hstack([X_transform, samsparse]) #combining numeric and text\n",
    "    \n",
    "    X_test=vectorizer.transform(test_x) #repeating above for test\n",
    "    samt=test.drop(removeList, axis=1).copy() #removing irrelevant\n",
    "    samsparset=scipy.sparse.csr_matrix(samt.to_sparse()) #sparsing numeric \n",
    "    surpriset=scipy.sparse.hstack([X_test, samsparset]) #combining numeric and text\n",
    "    \n",
    "    nb_classifier = MultinomialNB().fit(surprise, train_y)\n",
    "    y_nb_predicted = nb_classifier.predict(surpriset)\n",
    "    \n",
    "    predict_y=Series(y_nb_predicted).reset_index()[0]\n",
    "    df=pd.DataFrame()\n",
    "    df['Predicted']=predict_y\n",
    "    df['Actual']=test_y.reset_index()['High']\n",
    "    \n",
    "    print \"Percent Correct\\n\",round((df['Predicted']==df['Actual']).mean()*100,3)\n",
    "    print \"\\nConfusion Matrix\\n\",pd.crosstab(index=df['Actual'],columns=df['Predicted'])\n",
    "    print \"\\nProportion Table\\n\", pd.crosstab(index=df['Actual'],columns=df['Predicted']).apply(lambda r: r/r.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Correct\n",
      "79.421\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted     0     1\n",
      "Actual               \n",
      "0          1548   353\n",
      "1           443  1524\n",
      "\n",
      "Proportion Table\n",
      "Predicted         0         1\n",
      "Actual                       \n",
      "0          0.814308  0.185692\n",
      "1          0.225216  0.774784\n"
     ]
    }
   ],
   "source": [
    "rL=[\"Review\",\"stars\",\"High\"]\n",
    "yelper(rL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(sample['High'], n_folds=3, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Correct\n",
      "80.688\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted     0     1\n",
      "Actual               \n",
      "0          1596   313\n",
      "1           434  1525\n",
      "\n",
      "Proportion Table\n",
      "Predicted         0         1\n",
      "Actual                       \n",
      "0          0.836040  0.163960\n",
      "1          0.221542  0.778458\n"
     ]
    }
   ],
   "source": [
    "yelper(rL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Correct\n",
      "80.093\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted     0     1\n",
      "Actual               \n",
      "0          1577   390\n",
      "1           380  1521\n",
      "\n",
      "Proportion Table\n",
      "Predicted         0         1\n",
      "Actual                       \n",
      "0          0.801729  0.198271\n",
      "1          0.199895  0.800105\n"
     ]
    }
   ],
   "source": [
    "yelper(rL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Correct\n",
      "80.222\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted     0     1\n",
      "Actual               \n",
      "0          1588   382\n",
      "1           383  1515\n",
      "\n",
      "Proportion Table\n",
      "Predicted         0         1\n",
      "Actual                       \n",
      "0          0.806091  0.193909\n",
      "1          0.201791  0.798209\n"
     ]
    }
   ],
   "source": [
    "yelper(rL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Part D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawsentiment = pd.read_excel('Yelp_Review_Data_Results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawsentiment['True_Sentiment'] = rawsentiment['Pos Senti'] + rawsentiment['Neg Senti']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawsentiment['Actual'] = yelp['High']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Raw Sentiment, 0 defaults to low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Correct\n",
      "58.471\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted     0     1\n",
      "Actual               \n",
      "0          2354  4092\n",
      "1          4213  9339\n",
      "\n",
      "Proportion Table\n",
      "Predicted         0         1\n",
      "Actual                       \n",
      "0          0.365188  0.634812\n",
      "1          0.310877  0.689123\n"
     ]
    }
   ],
   "source": [
    "rawsentiment['Predicted']=0\n",
    "rawsentiment['Predicted'].ix[rawsentiment['True_Sentiment']>0]=1\n",
    "df=rawsentiment\n",
    "print \"Percent Correct\\n\",round((df['Predicted']==df['Actual']).mean()*100,3)\n",
    "print \"\\nConfusion Matrix\\n\",pd.crosstab(index=df['Actual'],columns=df['Predicted'])\n",
    "print \"\\nProportion Table\\n\", pd.crosstab(index=df['Actual'],columns=df['Predicted']).apply(lambda r: r/r.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Raw Sentiment, 0 defaults to high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Correct\n",
      "35.914\n",
      "\n",
      "Confusion Matrix\n",
      "Predicted      0     1\n",
      "Actual                \n",
      "0           5457   989\n",
      "1          11827  1725\n",
      "\n",
      "Proportion Table\n",
      "Predicted         0         1\n",
      "Actual                       \n",
      "0          0.846572  0.153428\n",
      "1          0.872713  0.127287\n"
     ]
    }
   ],
   "source": [
    "rawsentiment['Predicted']=0\n",
    "rawsentiment['Predicted'].ix[rawsentiment['True_Sentiment']<0]=1\n",
    "df=rawsentiment\n",
    "print \"Percent Correct\\n\",round((df['Predicted']==df['Actual']).mean()*100,3)\n",
    "print \"\\nConfusion Matrix\\n\",pd.crosstab(index=df['Actual'],columns=df['Predicted'])\n",
    "print \"\\nProportion Table\\n\", pd.crosstab(index=df['Actual'],columns=df['Predicted']).apply(lambda r: r/r.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Part E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DTMReviews = vectorizer.fit_transform(sample['Review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn.metrics.pairwise import cosine_similarity\n",
    "#def new_euclidean_distances(X, Y=None, Y_norm_squared=None, squared=False):\n",
    "#    return cosine_similarity(X,Y)\n",
    "\n",
    "# monkey patch (ensure cosine dist function is used)\n",
    "#from sklearn.cluster import k_means_k_means_.euclidean_distances\n",
    "#k_means_.euclidean_distances = new_euclidean_distances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster = sklearn.cluster.KMeans(n_clusters=2, random_state = 1)\n",
    "clusterout = Cluster.fit(DTMReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series_clusters = Series(clusterout.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample['Cluster'] = series_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.concat([sample, series_clusters], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>votes_cool</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>votes_useful</th>\n",
       "      <th>Cheap</th>\n",
       "      <th>Moderate</th>\n",
       "      <th>Expensive</th>\n",
       "      <th>VeryExpensive</th>\n",
       "      <th>American</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>...</th>\n",
       "      <th>Italian</th>\n",
       "      <th>Greek</th>\n",
       "      <th>Mediterranean</th>\n",
       "      <th>Mexican</th>\n",
       "      <th>Thai</th>\n",
       "      <th>Vietnamese</th>\n",
       "      <th>Others</th>\n",
       "      <th>Review</th>\n",
       "      <th>High</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Perfectly complimenting their slightly funky  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reminds me of back home in Chicago. Love the a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I LOVE this pizza!  It s the best I have had i...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This was an interesting dinner.  First  it was...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I love this place and go there like a regular....</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars  votes_cool  votes_funny  votes_useful  Cheap  Moderate  Expensive  \\\n",
       "0      4           1            0             2      0         1          0   \n",
       "1      5           1            0             1      0         1          0   \n",
       "2      5           0            0             4      1         0          0   \n",
       "3      4           0            0             2      0         1          0   \n",
       "4      5           1            1             2      0         1          0   \n",
       "\n",
       "   VeryExpensive  American  Chinese   ...     Italian  Greek  Mediterranean  \\\n",
       "0              0         1        0   ...           0      0              0   \n",
       "1              0         0        0   ...           1      0              0   \n",
       "2              0         0        0   ...           1      0              0   \n",
       "3              0         1        0   ...           0      0              0   \n",
       "4              0         0        0   ...           0      0              0   \n",
       "\n",
       "   Mexican  Thai  Vietnamese  Others  \\\n",
       "0        0     0           0       0   \n",
       "1        0     0           0       0   \n",
       "2        0     0           0       0   \n",
       "3        1     0           0       0   \n",
       "4        0     0           0       0   \n",
       "\n",
       "                                              Review  High  Cluster  \n",
       "0  Perfectly complimenting their slightly funky  ...     1        1  \n",
       "1  reminds me of back home in Chicago. Love the a...     1        1  \n",
       "2  I LOVE this pizza!  It s the best I have had i...     1        1  \n",
       "3  This was an interesting dinner.  First  it was...     1        0  \n",
       "4  I love this place and go there like a regular....     1        1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      "Cluster     0     1\n",
      "High               \n",
      "0        3422  3024\n",
      "1        2295  4151\n",
      "\n",
      "Percent Correct\n",
      "41.258\n",
      "\n",
      "Proportion Table\n",
      "Cluster         0         1\n",
      "High                       \n",
      "0        0.530872  0.469128\n",
      "1        0.356035  0.643965\n"
     ]
    }
   ],
   "source": [
    "print \"Confusion Matrix \\n\", pd.crosstab(index=sample['High'],columns=sample['Cluster'])\n",
    "print \"\\nPercent Correct\\n\", round((sample['High']!=sample['Cluster']).mean()*100,3)\n",
    "print \"\\nProportion Table\\n\", pd.crosstab(index=sample['High'],columns=sample['Cluster']).apply(lambda r: r/r.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Part F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from nltk import download\n",
    "#from textblob_aptagger import PerceptronTagger\n",
    "#from textblob import Blobber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'This location is out of business. I drove by it on my way to Costco and it just has a giant for lease sign.',\n",
       " u'= = = = = = CLOSED = = = = = =This JB s location  with it s poor building layout  poor service & mediocre food finally folded.  Good riddance!     :-)']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews=yelp['Review']\n",
    "reviews=reviews.str.decode(\"utf-8\")\n",
    "reviews_high = reviews[yelp['High'] == 1].copy()\n",
    "reviews_low = reviews[yelp['High'] == 0].copy()\n",
    "reviews=list(reviews)\n",
    "reviews[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_high = reviews_high.map(word_tokenize)\n",
    "token_low = reviews_low.map(word_tokenize)\n",
    "token_high = list(token_high)\n",
    "token_low = list(token_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat_high = list(itertools.chain.from_iterable(token_high))\n",
    "flat_low = list(itertools.chain.from_iterable(token_low))\n",
    "high_lower = [t.lower() for t in flat_high if t.isalpha()]\n",
    "low_lower = [t.lower() for t in flat_low if t.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_set = set(high_lower)\n",
    "low_set = set(low_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_vc = Series(high_lower).value_counts()\n",
    "low_vc = Series(low_lower).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "high_clean = [word for word in high_vc.index if word not in stopwords.words('english')]\n",
    "low_clean = [word for word in low_vc.index if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag_high100 = pos_tag(high_clean[:100])\n",
    "tag_low100 = pos_tag(low_clean[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "high_noun = [word for word,tag in tag_high100 if tag == 'NN']\n",
    "low_noun = [word for word,tag in tag_low100 if tag == 'NN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def noun_extractor(series):\n",
    "    token = series.map(word_tokenize)\n",
    "    tag = token.map(pos_tag)\n",
    "    [x for x in tag]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
